steps:
# 1. Build Docker Image (關鍵需求 1)
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA', '.']

# 2. Push Image to Artifact Registry (關鍵需求 1)
- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA']

# 3. 提交 Pipeline Job 到 Vertex AI (關鍵需求 2)
# 我們直接用 gcloud 指令或 python script 提交，這裡用 python script 比較簡單
- name: 'python:3.12'
  entrypoint: 'bash'
  env:
    - 'TRAINING_IMAGE_URI=asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA'
  args:
    - '-c'
    - |
      # 安裝依賴 (同一行執行，確保環境一致)
      pip install kfp==2.15.2 google-cloud-pipeline-components google-cloud-aiplatform
      
      # 編譯 Pipeline (產生 pipeline.json)
      python pipeline.py \
        --project_id $PROJECT_ID \
        --bucket_name ${_BUCKET_NAME}
    
      python -c "
      import google.cloud.aiplatform as aip;
      aip.init(project='$PROJECT_ID', location='asia-east1');
      job = aip.PipelineJob(
          display_name='penguin-pipeline-$SHORT_SHA',
          template_path='pipeline.json',
          pipeline_root='gs://${_BUCKET_NAME}/pipeline_root', 
          parameter_values={
              'project_id': '$PROJECT_ID',
              'bucket_name': '${_BUCKET_NAME}',
          }
      )
      job.submit(
          service_account="${_MLOPS_SERVICE_ACCOUNT}"
      )
      "

images:
- 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY
