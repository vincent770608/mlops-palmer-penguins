steps:
# 1. Build Docker Image (關鍵需求 1)
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA', '.']

# 2. Push Image to Artifact Registry (關鍵需求 1)
- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA']

# 3. 提交 Pipeline Job 到 Vertex AI (關鍵需求 2)
# 我們直接用 gcloud 指令或 python script 提交，這裡用 python script 比較簡單
- name: 'python:3.12'
  entrypoint: 'bash'
  env:
    - 'TRAINING_IMAGE_URI=asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA'
    - 'BUCKET_NAME=${_BUCKET_NAME}'
  args:
    - '-c'
    - |
      pip install kfp==2.12.2 google-cloud-pipeline-components==2.22.0 google-cloud-aiplatform==1.132.0
      
      # 編譯 Pipeline (產生 pipeline.json)
      # 編譯時不需要傳 run_id，因為它是 Pipeline 的 "執行參數" (Runtime Parameter)
      # 這裡只要定義好結構即可
      python pipelines/pipeline.py --project_id $PROJECT_ID
    
      python -c "
      import google.cloud.aiplatform as aip;
      aip.init(project='$PROJECT_ID', location='asia-east1');
      job = aip.PipelineJob(
          display_name='penguin-pipeline-$SHORT_SHA',
          template_path='pipeline.json',
          pipeline_root='gs://${_BUCKET_NAME}/pipeline_root', 
          parameter_values={
              'project_id': '$PROJECT_ID',
              'run_id': '$SHORT_SHA',
          }
      )
      job.submit(
          service_account='${_MLOPS_SERVICE_ACCOUNT}'
      )
      "

images:
- 'asia-east1-docker.pkg.dev/$PROJECT_ID/mlops-palmer-penguins/penguin-train:$SHORT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY
